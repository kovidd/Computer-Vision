{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SIFT features (default settings):  1337\n"
     ]
    }
   ],
   "source": [
    "#COMPUTE_SIFT.PY\n",
    "# Sample solution code for computing SIFT feature pre-lab task\n",
    "\n",
    "import cv2\n",
    "\n",
    "class SiftDetector():\n",
    "    def __init__(self, norm=\"L2\", params=None):\n",
    "        self.detector=self.get_detector(params)\n",
    "        self.norm=norm\n",
    "\n",
    "    def get_detector(self, params):\n",
    "        if params is None:\n",
    "            params={}\n",
    "            params[\"n_features\"]=0\n",
    "            params[\"n_octave_layers\"]=3\n",
    "            params[\"contrast_threshold\"]=0.03\n",
    "            params[\"edge_threshold\"]=10\n",
    "            params[\"sigma\"]=1.6\n",
    "\n",
    "        detector = cv2.xfeatures2d.SIFT_create(\n",
    "                nfeatures=params[\"n_features\"],\n",
    "                nOctaveLayers=params[\"n_octave_layers\"],\n",
    "                contrastThreshold=params[\"contrast_threshold\"],\n",
    "                edgeThreshold=params[\"edge_threshold\"],\n",
    "                sigma=params[\"sigma\"])\n",
    "\n",
    "        return detector\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # TASK 1\n",
    "\n",
    "    # 1. Read image\n",
    "    image = cv2.imread(\"image1.jpg\")\n",
    "    cv2.imshow(\"Colour picture\", image)\n",
    "\n",
    "    # 2. Convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 3. Initialize SIFT detector\n",
    "    sift = SiftDetector()\n",
    "\n",
    "    # 4. Detect SIFT features\n",
    "    kp = sift.detector.detect(gray, None)\n",
    "\n",
    "    # 5. Visualize detected features\n",
    "    kp_gray = cv2.drawKeypoints(image, kp, gray)\n",
    "\n",
    "    # Print number of SIFT features detected\n",
    "    print(\"Number of SIFT features (default settings): \", len(kp))\n",
    "\n",
    "    cv2.imshow(\"Keypoints image\", kp_gray)\n",
    "    cv2.imwrite('Keypoints image.jpg', kp_gray)\n",
    "    cv2.waitKey(2000)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SIFT features:  231\n",
      "matches: 231\n"
     ]
    }
   ],
   "source": [
    "#TASK2.PY\n",
    "\n",
    "import cv2\n",
    "\n",
    "from compute_sift import SiftDetector\n",
    "\n",
    "\n",
    "# Parameters for SIFT initializations such that we find only 25% of keypoints\n",
    "params = {\n",
    "    'n_features': 0,    #update this to 100, to view only 100 keypoints\n",
    "    'n_octave_layers': 3,\n",
    "    'contrast_threshold': 0.08,  # updated threshold.This value will vary for different images to view 25% of keypoints.\n",
    "    'edge_threshold': 10,\n",
    "    'sigma': 1.6\n",
    "}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 1. Read image\n",
    "    image = cv2.imread(\"image2.jpg\")\n",
    "\n",
    "    # 2. Convert image to grayscale\n",
    "    grayImageOrig = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Initialize SIFT detector\n",
    "    sift = SiftDetector(params=params)\n",
    "\n",
    "    # Store SIFT keypoints of original image in a Numpy array\n",
    "    kp,des1 = sift.detector.detectAndCompute(grayImageOrig, None)\n",
    "\n",
    "    kp_gray = cv2.drawKeypoints(image, kp, grayImageOrig)\n",
    "    cv2.imshow(\"Original keypoints\", kp_gray)\n",
    "    cv2.imwrite(\"Task_2_Original-keypoints.jpg\", kp_gray)\n",
    "    print(\"Number of SIFT features: \", len(kp))\n",
    "    cv2.waitKey(2000)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    #Upscale the image\n",
    "    scale_percent = 110  # percent of original size\n",
    "    width = int(image.shape[1] * scale_percent / 100)\n",
    "    height = int(image.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    # resize image\n",
    "    resizedImage = cv2.resize(grayImageOrig, dim, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Compute SIFT features for rescaled image\n",
    "    kp_,des2 = sift.detector.detectAndCompute(resizedImage, None)\n",
    "    kp_gray_ = cv2.drawKeypoints(resizedImage, kp_, resizedImage)\n",
    "    cv2.imshow(\"Upscaled keypoints\", kp_gray_)\n",
    "    cv2.imwrite(\"Task_2_Upscaled-keypoints.jpg\", kp_gray)\n",
    "    cv2.waitKey(2000)\n",
    "    cv2.destroyAllWindows()\n",
    "    # BFMatcher with default params\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "    print('matches:',len(matches))\n",
    "\n",
    "    # Apply ratio test\n",
    "    \"\"\"This test rejects poor matches by computing the ratio between the best and second-best match. \n",
    "    If the ratio is below some threshold, the match is discarded as being low-quality.\"\"\"\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.80 * n.distance:\n",
    "            good.append([m])\n",
    "\n",
    "    # Draw matches\n",
    "    result = cv2.drawMatchesKnn(\n",
    "        grayImageOrig, kp,\n",
    "        resizedImage, kp_,\n",
    "        good, None, flags=2)\n",
    "\n",
    "    cv2.imshow(\"Matched points\", result)\n",
    "    cv2.imwrite(\"Task_2_Matched-points.jpg\", result)\n",
    "    cv2.waitKey(2000)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SIFT features:  132\n"
     ]
    }
   ],
   "source": [
    "#TASK3.PY\n",
    "# Sample solution for lab task 3 (SIFT robustness to changes in rotation)\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from compute_sift import SiftDetector\n",
    "\n",
    "import sys\n",
    "# Parameters for SIFT initializations such that we find only 25% of keypoints\n",
    "params = {\n",
    "    'n_features': 0,    #update this to 100, to view only 100 keypoints\n",
    "    'n_octave_layers': 3,\n",
    "    'contrast_threshold': 0.1,  # updated threshold.This value will vary for different images to view 25% of keypoints.\n",
    "    'edge_threshold': 10,\n",
    "    'sigma': 1.6\n",
    "}\n",
    "\n",
    "# Rotate an image\n",
    "#\n",
    "# image: image to rotate\n",
    "# x:     x-coordinate of point we wish to rotate around\n",
    "# y:     y-coordinate of point we wish to rotate around\n",
    "# angle: degrees to rotate image by\n",
    "#\n",
    "# Returns a rotated copy of the original image\n",
    "def rotate(image, x, y, angle):\n",
    "    rot_matrix = cv2.getRotationMatrix2D((x, y), angle, 1.0)\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    return cv2.warpAffine(image, rot_matrix, (w, h))\n",
    "\n",
    "\n",
    "# Get coordinates of center point.\n",
    "#\n",
    "# image:  Image that will be rotated\n",
    "# return: (x, y) coordinates of point at center of image\n",
    "def get_img_center(image):\n",
    "    height, width = image.shape[:2]\n",
    "    center = height // 2, width // 2\n",
    "\n",
    "    return center\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Read image with OpenCV and convert to grayscale\n",
    "    image = cv2.imread(\"Image1.jpg\")\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Initialize SIFT detector\n",
    "    sift = SiftDetector(params=params)\n",
    "\n",
    "    # Store SIFT keypoints of original image in a Numpy array\n",
    "    kp1, des1 = sift.detector.detectAndCompute(gray, None)\n",
    "    OrigKeypoints = cv2.drawKeypoints(gray, kp1, None)\n",
    "    print(\"Number of SIFT features: \", len(kp1))\n",
    "    cv2.imshow(\"Original keypoints\", OrigKeypoints)\n",
    "    cv2.imwrite(\"Task_3_Original-keypoints.jpg\", OrigKeypoints)\n",
    "    cv2.waitKey(2000)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # center of image points. 'img_center' is in (Y, X) order.\n",
    "    img_center = get_img_center(gray)\n",
    "    x_coord = img_center[1]\n",
    "    y_coord = img_center[0]\n",
    "\n",
    "    # Degrees with which to rotate image\n",
    "    angle = 90\n",
    "\n",
    "    # Rotate image\n",
    "    rotate_gray = rotate(gray, x_coord, y_coord, angle)\n",
    "\n",
    "    # Compute SIFT features for rotated image\n",
    "    kp2, des2 = sift.detector.detectAndCompute(rotate_gray, None)\n",
    "    kp_gray = cv2.drawKeypoints(rotate_gray, kp2, None)\n",
    "\n",
    "    # BFMatcher with default params\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "    cv2.imshow(\"Rotated keypoints\", kp_gray)\n",
    "    cv2.imwrite(\"Task_3_Rotated-keypoints.jpg\", kp_gray)\n",
    "    cv2.waitKey(2000)\n",
    "    cv2.destroyAllWindows()\n",
    "    # Apply ratio test\n",
    "    \"\"\"This test rejects poor matches by computing the ratio between the best and second-best match. \n",
    "    If the ratio is below some threshold, the match is discarded as being low-quality.\"\"\"\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.80 * n.distance:\n",
    "            good.append([m])\n",
    "\n",
    "    # cv2.drawMatchesKnn\n",
    "    result = cv2.drawMatchesKnn(\n",
    "        gray, kp1,\n",
    "        rotate_gray, kp2,\n",
    "        good, None, flags=2)\n",
    "\n",
    "    cv2.imshow(\"Matched points\", result)\n",
    "    cv2.imwrite(\"Task_3_Matched-points.jpg\", result)\n",
    "    cv2.waitKey(2000)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to plot to make look better\n",
    "# plt.imshow(img, cmap=cm.gray, vmin=0, vmax=255)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
